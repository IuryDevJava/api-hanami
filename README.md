# Projeto Hanami Backend ‚Äî API de An√°lise de Dados

API backend desenvolvida em **Java com Spring Boot** para processamento de arquivos **CSV/XLSX** e gera√ß√£o de **relat√≥rios anal√≠ticos de vendas**.  
Este projeto faz parte do **Projeto Hanami**, uma iniciativa de impacto social voltada ao uso de tecnologia para an√°lise de dados.

---

## üìå Vis√£o Geral do Projeto

- **Prazo total:** 40 dias
- **Metodologia:** Desenvolvimento incremental por sprints
- **Sprint atual:** Sprint 1 ‚Äì Funda√ß√£o e Setup do Projeto
- **Status atual:** Finalizada

### üéØ Objetivo Geral
Desenvolver uma API robusta capaz de:
- Receber arquivos CSV/XLSX
- Processar dados de vendas
- Armazenar informa√ß√µes em banco de dados
- Gerar relat√≥rios anal√≠ticos

---

## üóÇÔ∏è Planejamento por Sprints

### Sprint 1 ‚Äî Funda√ß√£o e In√≠cio do Desenvolvimento
| Foco Principal | Entregas |
|---------------|---------|
| Setup do projeto e arquitetura base | Estrutura inicial do projeto |
| Configura√ß√£o de ambiente | Perfis `dev` e `prod` |
| In√≠cio do backend | Parser de dados e endpoint de upload |
| Persist√™ncia | Entidades e reposit√≥rios iniciais |

### Sprint 2 ‚Äî Consolida√ß√£o e Deploy *(planejada)*
| Foco Principal | Entregas |
|---------------|---------|
| Finaliza√ß√£o da l√≥gica de an√°lise | Algoritmos completos |
| Relat√≥rios | Gera√ß√£o de relat√≥rios PDF |
| Documenta√ß√£o | README final e instru√ß√µes de uso |
| Deploy | Ambiente produtivo |

> üîé **Observa√ß√£o:** A Sprint 2 ser√° detalhada ap√≥s a conclus√£o da Sprint 1.

---

## üõ†Ô∏è Tecnologias Utilizadas

- **Java 17**
- **Spring Boot**
- **MySQL**
- **Maven**

---

## üìÅ Estrutura do Projeto

```text
src/main/java/com/hanami/iurydev/apiHanami
‚îú‚îÄ‚îÄ controller     # Camada de controle (endpoints REST)
‚îú‚îÄ‚îÄ dto            # Objetos de transfer√™ncia de dados
‚îú‚îÄ‚îÄ entity
‚îÇ   ‚îú‚îÄ‚îÄ embeddable # Objetos incorpor√°veis
‚îÇ   ‚îú‚îÄ‚îÄ enums      # Enumera√ß√µes do dom√≠nio
‚îÇ   ‚îî‚îÄ‚îÄ Venda      # Entidade principal de vendas
‚îú‚îÄ‚îÄ repository     # Interfaces JPA
‚îú‚îÄ‚îÄ service        # Regras de neg√≥cio
‚îî‚îÄ‚îÄ ApiHanamiApplication
```
---

## Configura√ß√£o para ambiente de desenvolvimento e produ√ß√£o
### V√° em resources e crie um arquivo application-dev.properties adicione:
```
    spring.datasource.url=jdbc:mysql://localhost:3306/hanamiapidb
    spring.datasource.username=seu-login-mysql
    spring.datasource.password=sua-senha-mysql
    
    spring.jpa.database-platform=org.hibernate.dialect.MySQLDialect
    spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
    spring.jpa.show-sql=true
    spring.jpa.hibernate.ddl-auto=update
    
    # Aumenta o limite de tamanho do arquivo individual
    spring.servlet.multipart.max-file-size=50MB
    
    # Aumenta o limite total da requisi√ß√£o (arquivo + dados extras)
    spring.servlet.multipart.max-request-size=50MB
    
    spring.jackson.date-format=yyyy-MM-dd
    spring.jackson.time-zone=America/Sao_Paulo
``` 

### Na mesma pasta crie um arquivo application-prod.properties(para ambiente de produ√ß√£o) adicione:
``` 
    spring.datasource.url=jdbc:mysql://${MYSQLHOST}:${MYSQLPORT}/${MYSQLDATABASE}
    spring.datasource.username=${MYSQLUSER}
    spring.datasource.password=${MYSQLPASSWORD}
    
    spring.jpa.hibernate.ddl-auto=update
    spring.datasource.driver-class-name=com.mysql.cj.jdbc.Driver
    spring.jpa.show-sql=false
    spring.jpa.properties.hibernate.format_sql=true
    
    spring.jackson.date-format=yyyy-MM-dd
    spring.jackson.time-zone=America/Sao_Paulo
```

### No application.properties adicione:
```
    spring.profiles.active=dev
```

---

### ‚ñ∂Ô∏è Como Rodar o Projeto
#### Pr√©-requisitos
- Java 17
- MySQL

**Passo a passo**
1. Clone o reposit√≥rio
```bash
   git clone https://github.com/IuryDevJava/api-hanami.git
```

2. Entre no diret√≥rio
```bash
   cd api-hanami
```

3. Execute a aplica√ß√£o
```bash
   ./mvnw spring-boot:run
```

---

### Veja se as depend√™ncias necess√°rias para a leitura de arquivos est√£o no arquivo pom.xml
```xml
   <!-- Leitura de arquivos XLSX -->
    <dependency>
      <groupId>org.apache.poi</groupId>
      <artifactId>poi-ooxml</artifactId>
      <version>5.2.3</version>
    </dependency>
    
    <!-- Leitura de arquivos CSV -->
    <dependency>
      <groupId>com.opencsv</groupId>
      <artifactId>opencsv</artifactId>
      <version>5.5.2</version>
    </dependency>
```

---

### Endpoints REST - Sprint 1
#### Upload de Arquivo de Vendas
**Endpoint respons√°vel por receber arquivos CSV ou XLSX, validar os dados, processar as vendas e persistir no banco de dados**

---

*Post /vendas/upload*
#### Descri√ß√£o
#### Realiza o upload de um arquivo CSV ou XLSX contendo dados de vendas

- **Valida a estrutura do arquivo**
- **Valida regras de neg√≥cio campo a campo**
- **Evita duplicidade por id_transacao**
- **Persiste apenas registros v√°lidos**
- **Marca registros inv√°lidos com observa√ß√µes**

---

#### Requisi√ß√£o

- **URL: /vendas/upload**
- **M√©todo: POST**
- **Content-Type: multipart/form-data**

#### Par√¢metro (Body)
| Nome                     | Tipo | descri√ß√£o | 
|--------------------------|------|-----------|
| file                     | File | Arquivo CSV ou XLSX com os dados de vendas |

---

#### Chamada (Postman)

**Body**
- **Type: form-data**
- **Key: file**
- **Type: File**
- **Value: vendas_ficticias_10000_linhas.csv**

---

### Respostas da API - m√©todos POST
#### ‚úÖ 200 OK - Upload feito com sucesso
##### Retornado quando o arquivo √© processado de forma correta e cont√™m registros validados
```json
   {
  "status": "sucesso",
  "linhas_processadas": 10000
   }
```

---

#### ‚ö†Ô∏è 200 OK ‚Äî Nenhuma nova linha processada
##### Retornado quando o arquivo √© v√°lido, mas n√£o h√° novas vendas para persistir (ex: dados duplicados)
```json
   {
  "status": "Aviso: Nenhuma nova linha processada",
  "linhas_processadas": 0
   }
```

---

#### 400 Bad Request ‚Äî Arquivo n√£o enviado
##### Retornado quando o par√¢metro file n√£o √© enviado ou est√° vazio
```json
   {
  "status": "erro",
  "linhas_processadas": 0
   }
```

---

#### 422 Unprocessable Entity - Estrutura inv√°lida
##### Retornado quando o arquivo n√£o possui colunas obrigat√≥rias.
```json
   {
  "status": "Coluna obrigat√≥ria ausente: id_transacao",
  "linhas_processadas": 0
   }
```

---

### M√©todos GET 
##### {{base_url}}/vendas/reports/sales-summary - Retorna total de vendas e a m√©dia por transa√ß√£o.
```json
   {
  "receita_liquida": 5243176617.89,
  "lucro_bruto": 3099751358.11,
  "total_vendas": 8342927976.00,
  "media_por_transacao": 928849.70,
  "custo_total": 5243176617.89,
  "numero_transacoes": 8982
   }
```

---

##### {{base_url}}/vendas/reports/product-analysis - Retorna uma lista de produtos sem ordena√ß√£o.
```json
   [
  {
    "nome_produto": "Carregador Wireless",
    "quatidade_vendida": 1006,
    "total_arrecadado": 288235871.00
  },
  {
    "nome_produto": "iPhone 15",
    "quatidade_vendida": 787,
    "total_arrecadado": 246201201.00
  },
  {
    "nome_produto": "Apple Watch",
    "quatidade_vendida": 858,
    "total_arrecadado": 249837283.00
  }
  ]
```

---

##### {{base_url}}/vendas/reports/product-analysis?sort_by=quantidade - Retorna os produtos de forma ordenada e por quantidade.
```json
   [
  {
    "nome_produto": "Cabo USB-C",
    "quatidade_vendida": 1061,
    "total_arrecadado": 339386041.00
  },
  {
    "nome_produto": "Webcam HD",
    "quatidade_vendida": 1026,
    "total_arrecadado": 319378902.00
  },
  {
    "nome_produto": "Carregador Wireless",
    "quatidade_vendida": 1006,
    "total_arrecadado": 288235871.00
  }
  ]
```

---

##### {{base_url}}/vendas/reports/product-analysis?sort_by=valor - Retorna os produtos de forma ordenada e por valor.
```json
   [
  {
    "nome_produto": "Cabo USB-C",
    "quatidade_vendida": 1061,
    "total_arrecadado": 339386041.00
  },
  {
    "nome_produto": "Webcam HD",
    "quatidade_vendida": 1026,
    "total_arrecadado": 319378902.00
  },
  {
    "nome_produto": "Chromecast",
    "quatidade_vendida": 934,
    "total_arrecadado": 294529780.00
  }
  ]
```

---

##### {{base_url}}/vendas/reports/financial-metrics - Retorna um JSON com lucro_bruto, receita_liquida e custo_total.
```json
   {
  "receita_liquida": 5243176617.89,
  "lucro_bruto": 3099751358.11,
  "custo_total": 5243176617.89
   }
```

---

### Regras de Valida√ß√£o Aplicadas
#### Durante o processamento do arquivo, s√£o aplicadas valida√ß√µes como:

- **Formato do id_transacao (ex: TXN12345678)**
- **Margem de lucro m√≠nima e m√°xima**
- **Idade do cliente**
- **Formato de IDs de cliente, produto e vendedor**
- **Datas v√°lidas**
- **Campos obrigat√≥rios n√£o nulos**
- **Enumera√ß√µes normalizadas (canal de venda, forma de pagamento, regi√£o, status de entrega)**

---

### Banco de Dados MySQL
#### Modelo de Dados
#### A aplica√ß√£o utiliza o modelo de persist√™ncia onde os dados do Produto s√£o tratados como objetos incorpor√°veis (@Embeddable), resultando em uma tabela √∫nica de vendas para otimiza√ß√£o de performance anal√≠tica.
#### Criar e usar o banco (n√£o esque√ßa que o nome do banco precisa ser o mesmo no arquivo properties em spring.datasource.url=jdbc:mysql://localhost:3306/hanamiapidb)
```sql
   CREATE DATABASE hanamiapidb;
   USE hanamiapidb;
```

#### Listar tabelas
```sql
   SHOW TABLES;
```

#### Mostra o total de registros
```sql
   SELECT COUNT(*) FROM vendas;
```

#### Mostra em tabelas com dados os 10 primeiros registros
```sql
   SELECT * FROM vendas LIMIT 10;
```

#### Registros inv√°lidos
```sql
   SELECT id_transacao, observacao_validada
   FROM vendas
   WHERE processado_sucesso = false;
```

#### Estat√≠stica de processamento
```sql
   SELECT processado_sucesso, COUNT(*)
   FROM vendas
   GROUP BY processado_sucesso;
```

#### Limpar tabela
```sql
   DROP TABLE hanamiapidb.vendas;
```

#### Valida o endpoint que retorna os 6 campos. Faz a soma total, calcula a m√©dia e conta as transa√ß√µes
```sql
   SELECT
       SUM(valor_final) AS total_vendas,
       SUM(valor_final * (margem_lucro / 100)) AS lucro_bruto,
       SUM(valor_final) - SUM(valor_final * (margem_lucro / 100)) AS receita_liquida,
       SUM(valor_final - (valor_final * (margem_lucro / 100))) AS custo_total,
       AVG(valor_final) AS media_por_transacao,
       COUNT(*) AS numero_transacoes
   FROM vendas
   WHERE processado_sucesso = 1;
```

#### Valida a lista de produtos, a quantidade vendida e o total arrecadado em ordem decrescente
```sql
   SELECT
       nome_produto,
       COUNT(*) AS quantidade_vendida,
       SUM(valor_final) AS total_arrecadado
   FROM vendas
   WHERE processado_sucesso = 1
   GROUP BY nome_produto
   ORDER BY total_arrecadado DESC;
```

#### Retorna lucro_bruto, receita_liquida e custo_total
```sql
   SELECT
       SUM(valor_final * (margem_lucro / 100)) AS lucro_bruto,
       SUM(valor_final) - SUM(valor_final * (margem_lucro / 100)) AS receita_liquida,
       SUM(valor_final - (valor_final * (margem_lucro / 100))) AS custo_total
   FROM vendas
   WHERE processado_sucesso = 1;
```

---

### Logs e Observabilidade
#### Vis√£o Geral
#### A API utiliza logging estruturado para registrar eventos importantes durante o processamento de arquivos, facilitando:

- **Monitoramento da aplica√ß√£o**
- **Debug de erros**
- **Auditoria de processamento**
- **An√°lise de falhas em produ√ß√£o**

#### Insira em cima da classe controller a seguinte anota√ß√£o:
```java
   @Slf4j
   @RestController
   @RequestMapping("/vendas")
   public class VendaController {
   }
```

---

#### Logs de Sucesso
```text
   200 OK. Arquivo 'vendas_ficticias_10000_linhas.csv' foi processado com sucesso. Total: 10000 linhas
```

#### Quando ocorre?
- **Upload v√°lido**
- **Arquivo lido corretamente**
- **Processamento finalizado sem erros**

---

#### Logs de Erro - Requisi√ß√£o Inv√°lida (400)
```text
   Erro 400. Ao tentar fazer o upload sem arquivo foi retornado um erro
```

#### Quando ocorre?
- **Par√¢metro file n√£o enviado**
- **Arquivo vazio**

---

#### Logs de Erro ‚Äî Estrutura de Arquivo Inv√°lida (422)
```text
   Erro 422. Arquivo enviado n√£o cont√©m uma ou mais colunas obrigat√≥rias Coluna obrigat√≥ria ausente: id_transacao
```

#### Quando ocorre?
- **CSV/XLSX n√£o possui colunas obrigat√≥rias**
- **Estrutura incompat√≠vel com o parser**

---

#### Logs de Erro Cr√≠tico ‚Äî Falha Interna (500)
```text
   Erro cr√≠tico durante o processamento de upload
```

#### Quando ocorre?
- **Exce√ß√µes inesperadas**
- **Falhas de I/O, parsing ou banco de dados**

---

### Check-list Final de Fechamento da Sprint 1:
**[X] C√≥digo: O projeto compila sem erros? (Sim)**
**[X] Testes: Os endpoints no Postman batem com os resultados do SQL? (Sim)**
**[X] Documenta√ß√£o: O README reflete a realidade do c√≥digo? (Sim)**